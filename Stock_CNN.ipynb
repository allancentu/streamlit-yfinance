{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQuoUkg-JJVQ"
      },
      "source": [
        "# **Utilizando CNNs para análise gráfica de ações**\n",
        "O objetivo desse exercício é avaliar se CNNs são capazes de aprender comportamentos ligados a [análise gráfica](https://www.modalmais.com.br/blog/analise-grafica/) (também chamada de análise técnica), utilizados por economistas e profissionais do mercado financeiro para prever variações de curto-prazo em preços de ativos a partir de determinados padrões visuais examinados em gráficos que correlacionam volume e preços negociados.\n",
        "\n",
        "A análise gráfica é diferente da [análise fundamentalista](https://warren.com.br/magazine/analise-fundamentalista-e-tecnica/), focada em analisar fundamentos financeiros da empresa (crescimento de receita, composição do board, resultados operacionais, etc.) para definir estratégias de investimento de médio e longo-prazo.\n",
        "\n",
        "Seu principal objetivo é especular com preços no curto-prazo para ganhar com a volatilidade dos mercados. Por isso, é muito utilizada em negociações de day trade ou de ativos com alta volatilidade (ações, crypto, índices, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WgLiGAbAt05w",
        "outputId": "90714246-5b1c-49b1-fb03-cdbc2e97640d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/4.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q yfinance mplfinance tensorflow scikit-learn Pillow TA-Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcXcUUy83oj4"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas básicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rd\n",
        "import gc\n",
        "import shutil\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Bibliotecas financeiras e visuais\n",
        "import yfinance as yf\n",
        "import talib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import mplfinance as mpf\n",
        "\n",
        "# Tensorflow e Scikit-Learn\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import saving\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF7XA1NiJ-92"
      },
      "source": [
        "# Utils para gerar datasets\n",
        "Uma vez que a análise técnica é baseada na observação de comportamentos visuais em gráficos, usar CNNs se torna uma opção se elas forem capazes de aprender [os mesmos comportamentos visuais observados por economistas](https://www.warriortrading.com/candlestick-charts/) nessa modalidade.\n",
        "\n",
        "Para isso, é necessário gerar um dataset com um grande volume de dados de ativos financeiros representados visualmente, utilizando o padrão de [candlestick](https://www.jaspersoft.com/articles/what-is-a-candlestick-chart) comum nesse tipo de análise.\n",
        "\n",
        "Na célula abaixo, foram construídas quatro funções que realizam esse processo e transformam o resultado em um dataset treinável pelo Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25wneJM08tG1"
      },
      "outputs": [],
      "source": [
        "def download_data(tickers, period='1mo', interval='1d'):\n",
        "    \"\"\"\n",
        "    Baixa dados históricos de ações usando yfinance.\n",
        "\n",
        "    Args:\n",
        "        tickers (list ou str): Símbolos dos tickers (ex: ['AAPL', 'MSFT'] ou 'AAPL').\n",
        "        period (str): Período dos dados (ex: '1mo', '1d', '1y'). Padrão: '1mo'.\n",
        "        interval (str): Intervalo entre dados (ex: '1m', '5m', '1h', '1d'). Padrão: '1m'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Dados OHLCV com colunas em minúsculo e coluna 'ticker'.\n",
        "                     DataFrame vazio se não houver dados disponíveis.\n",
        "    \"\"\"\n",
        "    print(f\"Baixando dados: {tickers}, período={period}, intervalo={interval}\")\n",
        "\n",
        "    # Download em lote é mais eficiente que múltiplas requisições individuais\n",
        "    downloaded_data = yf.download(tickers, period=period, interval=interval, auto_adjust=True,\n",
        "                                  group_by='ticker', threads=True, progress=False)\n",
        "\n",
        "    if downloaded_data.empty:\n",
        "        print(\"Aviso: Nenhum dado disponível para download.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Ticker único: estrutura de colunas é diferente (sem MultiIndex)\n",
        "    if len(tickers) == 1:\n",
        "        downloaded_data.columns = downloaded_data.columns.str.lower()\n",
        "        downloaded_data['ticker'] = tickers[0]\n",
        "        print(f\"Download concluído: {len(downloaded_data)} registros para {tickers[0]}\")\n",
        "        return downloaded_data\n",
        "\n",
        "    # Múltiplos tickers: concatena dados de cada ticker individualmente\n",
        "    ticker_dataframes = []\n",
        "    for ticker_symbol in tickers:\n",
        "        if ticker_symbol not in downloaded_data.columns.get_level_values(0):\n",
        "            print(f\"Aviso: {ticker_symbol} não encontrado nos dados baixados.\")\n",
        "            continue\n",
        "\n",
        "        ticker_df = downloaded_data[ticker_symbol].copy()\n",
        "        if ticker_df.empty:\n",
        "            print(f\"Aviso: {ticker_symbol} sem dados disponíveis.\")\n",
        "            continue\n",
        "\n",
        "        ticker_df.columns = ticker_df.columns.str.lower()\n",
        "        ticker_df['ticker'] = ticker_symbol\n",
        "        ticker_dataframes.append(ticker_df)\n",
        "\n",
        "    result = pd.concat(ticker_dataframes, ignore_index=False) if ticker_dataframes else pd.DataFrame()\n",
        "    print(f\"Download concluído: {len(result)} registros totais para {len(ticker_dataframes)} tickers\")\n",
        "    return result\n",
        "\n",
        "def generate_samples(stock_data, tickers=None, num_samples=100, sample_size=20,\n",
        "                     horizon='next5', output_directory='/content/samples', batch_size=10):\n",
        "    \"\"\"\n",
        "    Gera imagens de candlestick para treinamento de modelos de ML.\n",
        "\n",
        "    Cada imagem contém uma janela temporal de candles e é rotulada com base no\n",
        "    movimento futuro do preço (up/down) após o horizonte especificado.\n",
        "    Para cada amostra, gera oito variações com estilos visuais diferentes.\n",
        "\n",
        "    Args:\n",
        "        stock_data (pd.DataFrame): Dados com colunas 'ticker', 'open', 'high', 'low', 'close', 'volume'.\n",
        "        tickers (list, optional): Tickers para gerar amostras. If None, uses all available tickers.\n",
        "        num_samples (int): Quantidade de amostras por ticker.\n",
        "        sample_size (int): Número de candles em cada imagem.\n",
        "        horizon (str): Janela futura para determinar o rótulo. Opções: 'next', 'next5', 'next15', 'next30', 'next60'.\n",
        "        output_directory (str): Diretório de saída das imagens. Padrão: '/content/samples'.\n",
        "        batch_size (int): Número de amostras processadas por lote (padrão: 10).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Metadados com colunas 'filename', 'label_ta' e 'label_calc' ('up' ou 'down').\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate_price_direction(ohlc_values, starting_index, sample_size, price_horizon):\n",
        "        \"\"\"\n",
        "        Calcula a direção do preço baseado em padrões de candlestick TA-Lib,\n",
        "        prioritizando padrões estritamente direcionais e usando a soma dos\n",
        "        sinais como desempate.\n",
        "        \"\"\"\n",
        "\n",
        "        # Categorize patterns based on the lists defined here\n",
        "        bullish_patterns = [\n",
        "            'CDL3STARSINSOUTH', 'CDL3WHITESOLDIERS', 'CDLCONCEALBABYSWALL',\n",
        "            'CDLHOMINGPIGEON', 'CDLLADDERBOTTOM', 'CDLMATCHINGLOW',\n",
        "            'CDLMATHOLD', 'CDLMORNINGDOJISTAR', 'CDLMORNINGSTAR',\n",
        "            'CDLPIERCING', 'CDLSTICKSANDWICH', 'CDLUNIQUE3RIVER',\n",
        "            'CDLHAMMER', 'CDLINVERTEDHAMMER', 'CDLDRAGONFLYDOJI', 'CDLGRAVESTONEDOJI'\n",
        "        ]\n",
        "\n",
        "        bearish_patterns = [\n",
        "            'CDL2CROWS', 'CDL3BLACKCROWS', 'CDLADVANCEBLOCK',\n",
        "            'CDLDARKCLOUDCOVER', 'CDLEVENINGDOJISTAR', 'CDLEVENINGSTAR',\n",
        "            'CDLIDENTICAL3CROWS', 'CDLINNECK', 'CDLONNECK',\n",
        "            'CDLSTALLEDPATTERN', 'CDLTHRUSTING', 'CDLUPSIDEGAP2CROWS',\n",
        "            'CDLSHOOTINGSTAR', 'CDLHANGINGMAN'\n",
        "        ]\n",
        "\n",
        "        both_patterns = [\n",
        "            'CDL3INSIDE', 'CDL3LINESTRIKE', 'CDL3OUTSIDE',\n",
        "            'CDLABANDONEDBABY', 'CDLBREAKAWAY', 'CDLCOUNTERATTACK',\n",
        "            'CDLDOJISTAR', 'CDLENGULFING', 'CDLGAPSIDESIDEWHITE',\n",
        "            'CDLHARAMI', 'CDLHARAMICROSS', 'CDLHIKKAKE',\n",
        "            'CDLHIKKAKEMOD', 'CDLKICKING', 'CDLKICKINGBYLENGTH',\n",
        "            'CDLRISEFALL3METHODS', 'CDLSEPARATINGLINES', 'CDLTASUKIGAP',\n",
        "            'CDLTRISTAR', 'CDLXSIDEGAP3METHODS'\n",
        "        ]\n",
        "\n",
        "\n",
        "        end_idx = starting_index + sample_size\n",
        "        # Analyze only the last 35% of the sample for pattern detection\n",
        "        analysis_start_in_sample = max(0, int(sample_size * 0.65)) # Start index within the sample slice\n",
        "\n",
        "        sample_data = ohlc_values[starting_index:end_idx]\n",
        "\n",
        "        # Check if sample_data is empty or not the expected size\n",
        "        if not sample_data.shape[0] == sample_size:\n",
        "            return (None, None)\n",
        "\n",
        "        sample_df = pd.DataFrame(sample_data, columns=ohlc_values.dtype.names)\n",
        "\n",
        "        # Extract OHLC\n",
        "        opens = sample_df['open'].values\n",
        "        highs = sample_df['high'].values\n",
        "        lows = sample_df['low'].values\n",
        "        closes = sample_df['close'].values\n",
        "\n",
        "        # Check if OHLC arrays are empty\n",
        "        if not opens.size > 0:\n",
        "             return (None, None)\n",
        "\n",
        "        # Get all candlestick pattern functions from TA-Lib\n",
        "        pattern_functions = [f for f in dir(talib) if f.startswith('CDL')]\n",
        "\n",
        "        strictly_bullish_found = False\n",
        "        strictly_bearish_found = False\n",
        "        overall_pattern_score = 0 # To be used for tie-breaking\n",
        "\n",
        "\n",
        "        # Analyze patterns within the analysis window (last 35% of sample)\n",
        "        for pattern_name in pattern_functions:\n",
        "            try:\n",
        "                result = getattr(talib, pattern_name)(opens, highs, lows, closes)\n",
        "\n",
        "                # Check for non-zero signals within the analysis window\n",
        "                analysis_window_results = result[analysis_start_in_sample:]\n",
        "                if np.any(analysis_window_results != 0):\n",
        "                    # Check if the pattern is strictly bullish or bearish\n",
        "                    if pattern_name in bullish_patterns:\n",
        "                        strictly_bullish_found = True\n",
        "                    elif pattern_name in bearish_patterns:\n",
        "                        strictly_bearish_found = True\n",
        "\n",
        "                    # Add the sum of non-zero results from the analysis window to the overall score\n",
        "                    overall_pattern_score += np.sum(analysis_window_results)\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                 # Catch potential errors with specific patterns or data\n",
        "                 # print(f\"Warning: Could not analyze pattern {pattern_name}: {e}\")\n",
        "                 pass # Ignore patterns that might fail for specific data\n",
        "\n",
        "\n",
        "        # Determine TA-lib direction based on the specified logic\n",
        "        talib_direction = 'neutral'\n",
        "\n",
        "        if strictly_bullish_found and not strictly_bearish_found:\n",
        "            talib_direction = 'up'\n",
        "        elif strictly_bearish_found and not strictly_bullish_found:\n",
        "            talib_direction = 'down'\n",
        "        elif strictly_bullish_found and strictly_bearish_found:\n",
        "            # Tie-breaker: if both strictly bullish and bearish patterns found, use overall score\n",
        "            if overall_pattern_score > 0:\n",
        "                talib_direction = 'up'\n",
        "            elif overall_pattern_score < 0:\n",
        "                talib_direction = 'down'\n",
        "            else:\n",
        "                talib_direction = 'neutral' # If scores are equal\n",
        "        # If neither strictly bullish nor strictly bearish patterns found,\n",
        "        # the talib_direction remains 'neutral' as initialized, unless 'both' patterns\n",
        "        # contributed to the overall_pattern_score in a significant way (which\n",
        "        # is handled by the tie-breaker logic if strictly patterns were also present).\n",
        "        # If only 'both' patterns were present, the score determines the direction.\n",
        "        elif not strictly_bullish_found and not strictly_bearish_found:\n",
        "             if overall_pattern_score > 0:\n",
        "                 talib_direction = 'up'\n",
        "             elif overall_pattern_score < 0:\n",
        "                 talib_direction = 'down'\n",
        "             else:\n",
        "                 talib_direction = 'neutral'\n",
        "\n",
        "\n",
        "        # Determine actual direction based on price movement\n",
        "        # Ensure future_idx is within the bounds of ohlc_values\n",
        "        future_idx = end_idx + price_horizon\n",
        "        actual_direction = None\n",
        "        if future_idx < len(ohlc_values) and closes.size > 0:\n",
        "            last_close = closes[-1]\n",
        "            future_close = ohlc_values[future_idx]['close']\n",
        "            actual_direction = 'up' if future_close > last_close else 'down'\n",
        "        elif closes.size > 0:\n",
        "             # If future data is not available, but sample data is, use neutral as a fallback\n",
        "             actual_direction = 'neutral'\n",
        "\n",
        "\n",
        "        return (talib_direction, actual_direction)\n",
        "\n",
        "    def normalize_sample(sample_candles, columns_to_normalize, column_rename_mapping):\n",
        "        \"\"\"Normaliza as colunas e renomeia para formato esperado pelo mplfinance.\"\"\"\n",
        "        sample_normalized = sample_candles.copy()\n",
        "        for column_name in columns_to_normalize:\n",
        "            column_min = sample_normalized[column_name].min()\n",
        "            column_max = sample_normalized[column_name].max()\n",
        "            if column_max != column_min and column_max != 0 and column_min != 0 and column_max is not None and column_min is not None:\n",
        "                sample_normalized[column_name] = (sample_normalized[column_name] - column_min) / (column_max - column_min)\n",
        "            else:\n",
        "                sample_normalized[column_name] = 0\n",
        "        sample_normalized.rename(columns=column_rename_mapping, inplace=True)\n",
        "        return sample_normalized\n",
        "\n",
        "    def generate_image_variations(sample_candles, ticker_symbol, images_generated, chart_styles,\n",
        "                                  output_path, label_ta, label_calc, image_metadata):\n",
        "        \"\"\"Gera oito variações de imagem com estilos diferentes.\"\"\"\n",
        "        style_indices = rd.sample(range(len(chart_styles)), 8)\n",
        "\n",
        "        for variation in range(1, 9):\n",
        "            image_filename = f\"{ticker_symbol}_sample_{images_generated + 1}_{variation}.png\"\n",
        "            image_full_path = output_path / image_filename\n",
        "\n",
        "            selected_style = chart_styles[style_indices[variation - 1]]\n",
        "\n",
        "            volume = rd.choice([True, False])\n",
        "\n",
        "            plot_kwargs = dict(\n",
        "                data=sample_candles,\n",
        "                type='candle',\n",
        "                style=selected_style,\n",
        "                volume=volume,\n",
        "                figratio=(1, 1),\n",
        "                figsize=(3, 3),\n",
        "                returnfig=True\n",
        "            )\n",
        "\n",
        "            chart_figure, chart_axes = mpf.plot(**plot_kwargs)\n",
        "\n",
        "            # Remove eixos para focar apenas nos padrões visuais\n",
        "            for axis in chart_axes:\n",
        "                ymin, ymax = axis.get_ylim()\n",
        "                if ymin == ymax:\n",
        "                  axis.set_ylim(ymin - 0.5, ymax + 0.5)\n",
        "                axis.set_yticks([])\n",
        "                axis.set_xticks([])\n",
        "                axis.set_ylabel(\"\")\n",
        "\n",
        "            chart_figure.savefig(image_full_path, dpi=100, bbox_inches='tight')\n",
        "            plt.close(chart_figure)\n",
        "\n",
        "            del chart_figure, chart_axes\n",
        "            image_metadata.append({\n",
        "                'filename': str(image_full_path.resolve()),\n",
        "                'label_ta': label_ta,\n",
        "                'label_calc': label_calc\n",
        "            })\n",
        "\n",
        "    def process_batch(batch_indices, ticker_data_memmap, ticker_symbol, images_generated_start,\n",
        "                      chart_styles, output_path, columns_to_normalize, column_rename_mapping,\n",
        "                      price_horizon, sample_size, ohlc_memmap):\n",
        "        \"\"\"Processa um lote de amostras.\"\"\"\n",
        "        batch_metadata = []\n",
        "        images_generated = images_generated_start\n",
        "\n",
        "        for starting_index in batch_indices:\n",
        "            # Extrai amostra do memmap\n",
        "            sample_data = ticker_data_memmap[starting_index:starting_index + sample_size]\n",
        "\n",
        "            if not sample_data.shape[0] == sample_size:\n",
        "                 print(f\"  Aviso: Sample data has incorrect size ({sample_data.shape[0]} instead of {sample_size}) - skipping sample at index {starting_index}\")\n",
        "                 continue\n",
        "\n",
        "            sample_candles = pd.DataFrame(sample_data, columns=ticker_data_memmap.dtype.names)\n",
        "\n",
        "\n",
        "            # Cria DatetimeIndex para mplfinance\n",
        "            sample_candles.index = pd.date_range(start='2020-01-01', periods=len(sample_candles), freq='D')\n",
        "\n",
        "            if len(sample_candles) != sample_size or sample_candles.isnull().any().any():\n",
        "                print(f\"  Aviso: Sample data is null or has incorrect size ({len(sample_candles)}) - skipping sample at index {starting_index}\")\n",
        "                continue\n",
        "\n",
        "            # Calcula direção do preço usando memmap - retorna tupla (label_ta, label_calc)\n",
        "            direction_tuple = calculate_price_direction(ohlc_memmap, starting_index, sample_size, price_horizon)\n",
        "            if direction_tuple[0] is None or direction_tuple[1] is None:\n",
        "                # print(f\"  Aviso: Could not calculate price direction for sample at index {starting_index} - skipping sample\")\n",
        "                continue # Skip samples where direction cannot be calculated\n",
        "\n",
        "\n",
        "            label_ta, label_calc = direction_tuple\n",
        "\n",
        "            # Normalize sample only if label_calc is not None (meaning future data was available)\n",
        "            if label_calc is not None:\n",
        "                # Normaliza amostra\n",
        "                sample_candles = normalize_sample(sample_candles, columns_to_normalize, column_rename_mapping)\n",
        "            else:\n",
        "                # If future data is not available, we still generate the image but use neutral label\n",
        "                label_calc = 'neutral'\n",
        "                # Normaliza amostra\n",
        "                sample_candles = normalize_sample(sample_candles, columns_to_normalize, column_rename_mapping)\n",
        "\n",
        "\n",
        "            # Gera variações\n",
        "            try:\n",
        "                generate_image_variations(sample_candles, ticker_symbol, images_generated, chart_styles,\n",
        "                                          output_path, label_ta, label_calc, batch_metadata)\n",
        "\n",
        "                del sample_candles\n",
        "                images_generated += 1\n",
        "\n",
        "            except Exception as error:\n",
        "                print(f\"  Erro ao gerar imagem {images_generated + 1}: {error}\")\n",
        "                continue\n",
        "\n",
        "        gc.collect()\n",
        "        return batch_metadata, images_generated - images_generated_start\n",
        "\n",
        "    # Converte prediction_horizon string para inteiro\n",
        "    horizon_mapping = {\n",
        "        'next': 1,\n",
        "        'next5': 5,\n",
        "        'next15': 15,\n",
        "        'next30': 30,\n",
        "        'next60': 60\n",
        "    }\n",
        "    price_horizon = horizon_mapping.get(horizon, 5)\n",
        "\n",
        "    # Processamento sequencial (sem paralelização) minimiza uso de memória\n",
        "    # pois evita duplicação de dados entre processos\n",
        "\n",
        "    # Infere tickers if not provided\n",
        "    if tickers is None:\n",
        "        tickers = stock_data['ticker'].unique().tolist()\n",
        "\n",
        "    print(f\"\\nGerando imagens: {num_samples} amostras/ticker (8 variações cada), {sample_size} períodos/amostra\")\n",
        "    print(f\"Horizonte de previsão: {horizon} (t+{price_horizon})\")\n",
        "\n",
        "    image_metadata = []\n",
        "    output_path = Path(output_directory)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Available visual styles to diversify the dataset\n",
        "    chart_styles = ['binance', 'binancedark', 'blueskies', 'brasil', 'charles', 'checkers', 'classic', 'default',\n",
        "                    'ibd', 'kenan', 'mike', 'nightclouds', 'sas', 'starsandstripes', 'tradingview', 'yahoo']\n",
        "\n",
        "    columns_to_normalize = ['open', 'high', 'low', 'close', 'volume']\n",
        "    column_rename_mapping = {'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'}\n",
        "\n",
        "    for ticker_symbol in tickers:\n",
        "        print(f\"\\nProcessando {ticker_symbol}...\")\n",
        "        ticker_data = stock_data[stock_data['ticker'] == ticker_symbol].copy()\n",
        "\n",
        "        # Remove invalid values\n",
        "        ticker_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        ticker_data.dropna(inplace=True)\n",
        "\n",
        "        if ticker_data.empty:\n",
        "            print(f\"  {ticker_symbol}: Sem dados após limpeza - pulando ticker\")\n",
        "            continue\n",
        "\n",
        "        # Calculate maximum valid index\n",
        "        max_starting_index = len(ticker_data) - sample_size - price_horizon + 1\n",
        "        if max_starting_index <= 0:\n",
        "            print(f\"  {ticker_symbol}: Dados insuficientes ({len(ticker_data)} registros) - pulando ticker\")\n",
        "            continue\n",
        "\n",
        "        # Create memmap for ticker data (saves RAM)\n",
        "        temp_memmap_path = output_path / f\"temp_{ticker_symbol}.dat\"\n",
        "        ticker_data_array = ticker_data[['open', 'high', 'low', 'close', 'volume']].to_records(index=False)\n",
        "        ticker_data_memmap = np.memmap(temp_memmap_path, dtype=ticker_data_array.dtype,\n",
        "                                       mode='w+', shape=ticker_data_array.shape)\n",
        "        ticker_data_memmap[:] = ticker_data_array[:]\n",
        "        ticker_data_memmap.flush()\n",
        "\n",
        "        # Memmap for OHLC values (for calculate_price_direction)\n",
        "        ohlc_memmap = ticker_data_memmap\n",
        "\n",
        "        # Shuffle indices\n",
        "        available_indices = list(range(max_starting_index))\n",
        "        rd.shuffle(available_indices)\n",
        "\n",
        "        max_unique_samples = len(available_indices)\n",
        "        unique_samples_count = min(num_samples, max_unique_samples)\n",
        "\n",
        "        # First pass: generate unique samples in batches\n",
        "        used_indices = []\n",
        "        images_generated = 0\n",
        "\n",
        "        # Divide indices into batches\n",
        "        first_pass_indices = available_indices[:unique_samples_count]\n",
        "        batches = [first_pass_indices[i:i + batch_size] for i in range(0, len(first_pass_indices), batch_size)]\n",
        "\n",
        "        for batch in batches:\n",
        "            batch_metadata, batch_count = process_batch(\n",
        "                batch, ticker_data_memmap, ticker_symbol, images_generated,\n",
        "                chart_styles, output_path, columns_to_normalize, column_rename_mapping,\n",
        "                price_horizon, sample_size, ohlc_memmap\n",
        "            )\n",
        "            image_metadata.extend(batch_metadata)\n",
        "            images_generated += batch_count\n",
        "            used_indices.extend(batch)\n",
        "\n",
        "            # Force garbage collection after each batch\n",
        "            gc.collect()\n",
        "\n",
        "        # Second pass: repeat samples if necessary\n",
        "        if images_generated < num_samples and len(used_indices) > 0:\n",
        "            repeat_needed = num_samples - images_generated\n",
        "            print(f\"  Gerando {repeat_needed} amostras repetidas para atingir meta de {num_samples}\")\n",
        "\n",
        "            repeat_indices = [used_indices[rd.randint(0, len(used_indices) - 1)]\n",
        "                              for _ in range(repeat_needed)]\n",
        "            repeat_batches = [repeat_indices[i:i + batch_size] for i in range(0, len(repeat_indices), batch_size)]\n",
        "\n",
        "            for batch in repeat_batches:\n",
        "                batch_metadata, batch_count = process_batch(\n",
        "                    batch, ticker_data_memmap, ticker_symbol, images_generated,\n",
        "                    chart_styles, output_path, columns_to_normalize, column_rename_mapping,\n",
        "                    price_horizon, sample_size, ohlc_memmap\n",
        "                )\n",
        "                image_metadata.extend(batch_metadata)\n",
        "                images_generated += batch_count\n",
        "                gc.collect()\n",
        "\n",
        "        print(f\"  {ticker_symbol}: {images_generated} amostras geradas (8 variações cada = {images_generated * 8} imagens)\")\n",
        "\n",
        "        # Clean up memmap and temporary file\n",
        "        del ticker_data_memmap, ohlc_memmap\n",
        "        temp_memmap_path.unlink(missing_ok=True)\n",
        "        del ticker_data\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    print(f\"\\nGeração concluída: {len(image_metadata)} imagens totais. Exemplos aleatórios abaixo:\")\n",
        "\n",
        "    # Mostra quatro amostras aleatórias\n",
        "    if len(image_metadata) >= 4:\n",
        "        sample_indices = rd.sample(range(len(image_metadata)), 4)\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(6, 6), facecolor=\"white\")\n",
        "\n",
        "        for idx, ax_idx in enumerate(sample_indices):\n",
        "            row, col = idx // 2, idx % 2\n",
        "            img_path = image_metadata[ax_idx]['filename']\n",
        "            img = Image.open(img_path)\n",
        "            axes[row, col].imshow(img)\n",
        "            axes[row, col].set_title(f\"TA: {image_metadata[ax_idx]['label_ta']}, Calc: {image_metadata[ax_idx]['label_calc']}\", fontsize=10)\n",
        "            axes[row, col].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return pd.DataFrame(image_metadata)\n",
        "\n",
        "def merge_samples(dfs, label_column='label', download=False, file_name='dataset'):\n",
        "    \"\"\"\n",
        "    Consolida múltiplos DataFrames de metadados em um único dataset validado.\n",
        "\n",
        "    Opcionalmente cria um arquivo zip com metadados (CSV) e imagens para download\n",
        "    no Google Drive, facilitando backup e compartilhamento.\n",
        "\n",
        "    Args:\n",
        "        dfs (list): Lista de DataFrames com colunas 'filename' e label.\n",
        "        label_column (str): Nome da coluna de rótulos. Padrão: 'label'.\n",
        "        download (bool): Se True, cria zip e salva no Google Drive. Padrão: False.\n",
        "        file_name (str): Nome do arquivo zip (sem extensão). Padrão: 'dataset'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Dataset consolidado e limpo.\n",
        "    \"\"\"\n",
        "    print(\"\\nMesclando metadados...\")\n",
        "\n",
        "    # Remove DataFrames vazios antes de concatenar\n",
        "    non_empty_dataframes = [df for df in dfs if not df.empty]\n",
        "\n",
        "    if not non_empty_dataframes:\n",
        "        print(\"Erro: Nenhum dado válido para mesclar\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Valida presença da coluna de label em todos os DataFrames\n",
        "    for dataframe_index, dataframe in enumerate(non_empty_dataframes):\n",
        "        if label_column not in dataframe.columns:\n",
        "            raise ValueError(f\"Coluna '{label_column}' ausente no DataFrame {dataframe_index}.\")\n",
        "\n",
        "    combined_metadata = pd.concat(non_empty_dataframes, ignore_index=True)\n",
        "\n",
        "    print(f\"Total antes da limpeza: {len(combined_metadata)} amostras\")\n",
        "\n",
        "    rows_before_cleaning = len(combined_metadata)\n",
        "\n",
        "    # Cleaning: remove NaN, infinities, and empty strings\n",
        "    combined_metadata.dropna(inplace=True)\n",
        "    combined_metadata.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    combined_metadata.dropna(inplace=True)\n",
        "\n",
        "    # Remove empty strings or strings with only whitespace\n",
        "    for column_name in combined_metadata.columns:\n",
        "        if combined_metadata[column_name].dtype == 'object':\n",
        "            combined_metadata = combined_metadata[combined_metadata[column_name].str.strip().astype(bool)]\n",
        "\n",
        "    rows_after_cleaning = len(combined_metadata)\n",
        "    rows_removed = rows_before_cleaning - rows_after_cleaning\n",
        "\n",
        "    if rows_removed > 0:\n",
        "        print(f\"Removidas {rows_removed} entradas inválidas\")\n",
        "\n",
        "    print(f\"Total após limpeza: {rows_after_cleaning} amostras\")\n",
        "\n",
        "    # Export to Google Drive (Colab environment only)\n",
        "    if download:\n",
        "        print(\"\\nPreparando exportação para Google Drive...\")\n",
        "\n",
        "        drive_path = Path('/content/drive')\n",
        "        if not drive_path.exists() or not drive_path.is_mount():\n",
        "            print(\"Erro: Google Drive não montado. Execute: from google.colab import drive; drive.mount('/content/drive')\")\n",
        "            return combined_metadata\n",
        "\n",
        "        temp_dir = Path('/content/temp_dataset')\n",
        "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Save metadata as CSV\n",
        "        metadata_csv_path = temp_dir / 'metadata.csv'\n",
        "        combined_metadata.to_csv(metadata_csv_path, index=False)\n",
        "\n",
        "        # Create zip file with CSV and images\n",
        "        zip_filename = f\"{file_name}.zip\"\n",
        "        zip_path = temp_dir / zip_filename\n",
        "\n",
        "        missing_files = 0\n",
        "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            zipf.write(metadata_csv_path, arcname='metadata.csv')\n",
        "\n",
        "            # Add images preserving folder structure\n",
        "            for _, row in combined_metadata.iterrows():\n",
        "                filename_with_path = row['filename']\n",
        "                source_file = Path(filename_with_path)\n",
        "\n",
        "                if source_file.exists():\n",
        "                    zipf.write(source_file, arcname=str(source_file))\n",
        "                else:\n",
        "                    missing_files += 1\n",
        "\n",
        "        if missing_files > 0:\n",
        "            print(f\"Aviso: {missing_files} arquivos não encontrados\")\n",
        "\n",
        "        zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"Zip criado: {zip_size_mb:.2f} MB\")\n",
        "\n",
        "        # Move to Google Drive\n",
        "        drive_destination = Path('/content/drive/MyDrive') / zip_filename\n",
        "        shutil.move(str(zip_path), str(drive_destination))\n",
        "\n",
        "        print(f\"Dataset salvo: {drive_destination}\")\n",
        "\n",
        "        shutil.rmtree(temp_dir)\n",
        "\n",
        "    return combined_metadata\n",
        "\n",
        "def prepare_dataset(df, image_size=(128, 128), test_split=0.2, batch_size=32, label='label'):\n",
        "    \"\"\"\n",
        "    Prepara datasets de treino e teste usando ImageDataGenerator do Keras.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame com colunas 'filename' e 'label'.\n",
        "        image_size (tuple): Tamanho de redimensionamento (altura, largura). Padrão: (128, 128).\n",
        "        test_split (float): Proporção do teste (0.0 a 1.0). Padrão: 0.2.\n",
        "        batch_size (int): Tamanho do lote para processamento. Padrão: 32.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_generator, test_generator, label_encoder)\n",
        "            - train_generator/test_generator: Generators do Keras\n",
        "            - label_encoder: LabelEncoder para decodificar predições\n",
        "    \"\"\"\n",
        "    print(f\"\\nPreparando datasets: divisão treino/teste = {1-test_split:.0%}/{test_split:.0%}\")\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['encoded_label'] = label_encoder.fit_transform(df[label])\n",
        "\n",
        "    print(f\"Codificação dos labels: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
        "\n",
        "    # Stratified split\n",
        "    train_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=test_split,\n",
        "        stratify=df['encoded_label'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Divisão: {len(train_df)} treino, {len(test_df)} teste\")\n",
        "\n",
        "    # Normalization for training and testing\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Create generators from DataFrame\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='filename',\n",
        "        y_col=label,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filename',\n",
        "        y_col=label,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\nDatasets preparados com {len(train_generator.class_indices)} classes\")\n",
        "    print(f\"  Treino: {len(train_df)} imagens\")\n",
        "    print(f\"  Teste: {len(test_df)} imagens\")\n",
        "\n",
        "    return train_generator, test_generator, label_encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm1MYEsL7nb-"
      },
      "source": [
        "# Gerando datasets\n",
        "Utilizando as funções criadas acima, nessa seção são gerados datasets que podem ser utilizados para treinamento, validação e teste do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zirK6nbECBG"
      },
      "outputs": [],
      "source": [
        "## Definindo parâmetros para gerar datasets nas próximas células\n",
        "tickers = ['TLK', 'VTEX', 'TM', 'KB', 'TSM', 'SHG', 'MUFG', 'SONY', 'KEP', 'PKX', 'WF', 'QQQM', 'HDB', 'KT', 'MFG', 'SKM', 'IBN', 'HMC', 'PAM', 'LPL', 'TAK', 'GGAL', 'INFY', 'NVDA', 'IX', 'MSFT', 'AAPL', 'NMR', 'BABA', 'GOOG', 'WIT', 'AMZN', 'META', 'AVGO', 'LOMA', 'TSLA', 'RDY', 'CHT', 'WMT', 'ORCL', 'AMJB', 'ASX', 'LLY', 'NTES', 'V', 'GFI', 'SUPV', 'SPY', 'UMC', 'AU', 'NFLX', 'MA', 'XOM', 'JNJ', 'PLTR', 'COST', 'IVV', 'JD', 'ABBV', 'PBR', 'NVD', 'HD', 'ITUB', 'TCOM', 'BAC', 'AMD', 'PG', 'ASML', 'BIDU', 'UNH', 'GE', 'CVX', 'ERIC', 'ONC', 'TME', 'KO', 'SAP', 'CSCO', 'VALE', 'WFC', 'VTI', 'TMUS', 'IBM', 'MS', 'PM', 'CAT', 'QQQ', 'GS', 'ABT', 'AXP', 'CRM', 'HMY', 'NVS', 'MCD', 'RTX', 'MRK', 'MU', 'PEP', 'RY', 'TKC', 'DIS', 'APP', 'SHOP', 'TMO', 'UBER', 'AZN', 'BX', 'NVO', 'LI', 'ABEV', 'NOW', 'T', 'BLK', 'C', 'INTU', 'PDD', 'ARM', 'GEV', 'ANET', 'LRCX', 'QCOM', 'NEE', 'AMAT', 'HSBC', 'BKNG', 'VZ', 'SCHW', 'BBD', 'BEKE', 'INTC', 'BA', 'XPEV', 'TJX', 'AMGN', 'TXN', 'ISRG', 'SHEL', 'ACN', 'APH', 'DHR', 'SBSW', 'GILD', 'SPGI', 'ETN', 'BSX', 'SYK', 'PGR', 'ADBE', 'PANW', 'SPOT', 'PFE', 'COF', 'KLAC', 'LOW', 'UNP', 'GLD', 'TD', 'HON', 'IWF', 'SAN', 'NIO', 'MDT', 'CRWD', 'CEG', 'DE', 'VUG', 'EBR', 'HOOD', 'LMT', 'IBKR', 'ZTO', 'ADP', 'ADI', 'DASH', 'TTE', 'CB', 'WELL', 'KKR', 'BN', 'CMCSA', 'COP', 'UL', 'MO', 'SO', 'MELI', 'BHP', 'PLD', 'SE', 'SCCO', 'VRTX', 'SNY', 'VIV', 'BSBR', 'ENB', 'MMC', 'CVS', 'NKE', 'DELL', 'NEM', 'DUK', 'CP', 'HCA', 'MCK', 'CME', 'TT', 'BUD', 'PH', 'BAM', 'RBLX', 'BBVA', 'SBUX', 'HTHT', 'ICE', 'BERZ', 'GD', 'AEM', 'NOC', 'BMY', 'CDNS', 'WM', 'COIN', 'ORLY', 'BILI', 'AMT', 'RIO', 'MCO', 'MSTR', 'VTV', 'SBS', 'RCL', 'SHW', 'RELX', 'SNPS', 'BTI', 'SNOW', 'MMM', 'CI', 'VWO', 'MDLZ', 'EQIX', 'ELV', 'BNS', 'ESLT', 'AJG', 'HWM', 'AON', 'BZ', 'ECL', 'MSI', 'APO', 'ABNB', 'WMB', 'CMRC', 'DHIL', 'CAEP', 'LAW', 'BW', 'AGL', 'MBAV', 'MTW', 'DBVT', 'SVC', 'CNDT', 'WENN', 'AURA', 'VERI', 'GPAT', 'JELD', 'PFL', 'TCI', 'RDAG', 'BRBS', 'GCBC', 'ALF', 'SVCC', 'USNA', 'GIG', 'SMLR', 'HDSN', 'HIX', 'CEPT', 'BMRC', 'AMBC', 'TMCI', 'NCMI', 'BSRR', 'MYN', 'DDL', 'LEO', 'THH', 'MLAB', 'RM', 'ESEA', 'SGU', 'TTGT', 'SRDX', 'FRBA', 'CTGO', 'DDD', 'NPAC', 'CHCT', 'VKI', 'BNTC', 'TACO', 'OBE', 'CCIX', 'DCTH', 'EGY', 'CWBC', 'AMRN', 'ATEX', 'ACWV', 'PSBD', 'RPAY', 'VSTA', 'DFDV', 'MVF', 'EAD', 'EHAB', 'TWFG', 'XRX', 'GRRR', 'AONCW', 'LCTX', 'DVLT', 'GRVY', 'FPH', 'EOLS', 'GBLI', 'CIVB', 'SATL', 'MVIS', 'OTLY', 'RMNI', 'RAPT', 'LWAY', 'DPRO', 'IHRT', 'BNC', 'MITK', 'SDHY', 'ELVA', 'CYH', 'MUA', 'GBAB', 'NOA', 'VHI', 'PKE', 'IAT', 'HYLN', 'FBIZ', 'GNE', 'COFS', 'CTRA', 'HNST', 'GMRE', 'ASTL', 'BCAR', 'TRC', 'MSB', 'PBL', 'WEST', 'HBCP', 'CCRN', 'HITI', 'VOXR', 'SD', 'BSVN', 'MCS', 'FFA', 'DIN', 'KRRO', 'AUTL', 'SPIR', 'SOHU', 'DH', 'PDYN', 'SBC', 'EDN', 'ACB', 'PNNT', 'JOUT', 'SB', 'QSI', 'NMAI', 'GLRE', 'NLOP', 'BOC', 'KELYA', 'CAL', 'CMCO', 'ETB', 'DDI', 'EVN', 'PERI', 'VPG', 'WOW', 'IMMP', 'RRBI', 'GRIN', 'BFK', 'DFP', 'NNDM', 'KIDS', 'KRNY', 'EPSM', 'YORW', 'CARE', 'OPAL', 'ASC', 'IMXI', 'ETO', 'CVGW', 'AROW', 'NATH', 'XOMA', 'SWBI', 'GDEV', 'GLAD', 'MAMA', 'EBF', 'OLP', 'ENGN', 'NQP', 'SITC', 'FPI', 'FRA', 'ARKO', 'SPPP', 'CDZI', 'KFS', 'CBLL', 'PLG', 'CGEM', 'LXEO', 'NP', 'BAND', 'IYC', 'IGD', 'HPI', 'WEED', 'RCKT', 'PKST', 'PTLO', 'ADCT', 'NML', 'EQV', 'LPTH', 'FDMT', 'CYRX', 'AII', 'FFIC', 'ACNB', 'HQL', 'PACK', 'GTEN', 'GLDG', 'FULC', 'ANGO', 'MLR', 'BWMX', 'UMAC', 'RMR', 'FRPH', 'LE', 'IXP', 'ZKH', 'NFBK', 'EXI', 'NRIM', 'NGNE', 'FTK', 'EVAC', 'SRTA', 'ANSC', 'LZM', 'VREX', 'HELE', 'PACB', 'INVZ', 'PFIS', 'TWI', 'FFWM', 'IVR', 'NBB', 'ALMS', 'LZMH', 'NPFD', 'NET', 'TEVA', 'CTAS', 'BK', 'VGT']\n",
        "num_samples = 80\n",
        "sample_size = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3p0ivjPDuH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67056f19-5ac6-4263-dee1-b4d44a0d6b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando dados: ['WFC', 'RMR', 'ESEA', 'XPEV', 'MLR', 'PNNT', 'BFK', 'DH', 'ETN', 'GNE', 'AMGN', 'SNPS', 'BHP', 'WOW', 'DHIL', 'CCRN', 'ITUB', 'VTI', 'TME', 'SBS', 'AMZN', 'ACB', 'ACWV', 'UNP', 'LRCX'], período=5d, intervalo=1m\n",
            "Download concluído: 48750 registros totais para 25 tickers\n",
            "\n",
            "Gerando imagens: 80 amostras/ticker (8 variações cada), 15 períodos/amostra\n",
            "Horizonte de previsão: next5 (t+5)\n",
            "\n",
            "Processando WFC...\n",
            "  WFC: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando RMR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  RMR: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando ESEA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ESEA: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando XPEV...\n",
            "  XPEV: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando MLR...\n",
            "  MLR: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando PNNT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PNNT: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando BFK...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BFK: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando DH...\n",
            "  DH: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando ETN...\n",
            "  ETN: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando GNE...\n",
            "  GNE: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando AMGN...\n",
            "  AMGN: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando SNPS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  SNPS: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando BHP...\n",
            "  BHP: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando WOW...\n",
            "  WOW: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando DHIL...\n",
            "  Gerando 7 amostras repetidas para atingir meta de 80\n",
            "  DHIL: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando CCRN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  CCRN: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando ITUB...\n",
            "  ITUB: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando VTI...\n",
            "  VTI: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando TME...\n",
            "  TME: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando SBS...\n",
            "  SBS: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando AMZN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  AMZN: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando ACB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ACB: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando ACWV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n",
            "/usr/local/lib/python3.12/dist-packages/mplfinance/plotting.py:707: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  volumeAxes.set_ylim(vymin,vymax)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ACWV: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando UNP...\n",
            "  UNP: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Processando LRCX...\n",
            "  LRCX: 80 amostras geradas (8 variações cada = 640 imagens)\n",
            "\n",
            "Geração concluída: 16000 imagens totais. Exemplos aleatórios abaixo:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Gerando dataset inicial com 25 ações, 80 amostras por ação e 8 gráficos por amostra = 16.000 gráficos\n",
        "# Utilizando intervalos de 1min, em um período de 5d, com t+5 como horizonte (6min após o final da amostra)\n",
        "tickers_1 = rd.sample(tickers, 25)\n",
        "period = '5d'\n",
        "interval = '1m'\n",
        "horizon = 'next5'\n",
        "directory='/content/samples_1'\n",
        "\n",
        "stocks_1 = download_data(tickers_1, period=period, interval=interval)\n",
        "samples_1 = generate_samples(stocks_1, num_samples=num_samples, sample_size=sample_size, horizon=horizon, output_directory=directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a40GswgAEOwZ"
      },
      "outputs": [],
      "source": [
        "## Se for necessário/desejado, é possível gerar mais datasets para outros intervalos para adicionar variabilidade nos dados\n",
        "## Ao executar essa célula, são adicionados mais 48.000 gráficos ao dataset, totalizando 64.000 gráficos\n",
        "# Samples 2: Utilizando intervalos de 15min, em um período de 5d, com t+5 como horizonte (75min após o final da amostra)\n",
        "tickers_2 = rd.sample(tickers, 25)\n",
        "period = '5d'\n",
        "interval = '15m'\n",
        "horizon = 'next5'\n",
        "directory='/content/samples_2'\n",
        "stocks_2 = download_data(tickers_2, period=period, interval=interval)\n",
        "samples_2 = generate_samples(stocks_2, num_samples=num_samples, sample_size=sample_size, horizon=horizon, output_directory=directory)\n",
        "\n",
        "# Samples 3: Utilizando intervalos de 1d, em um período de 2y, com t+5 como horizonte (6d após o final da amostra)\n",
        "tickers_3 = rd.sample(tickers, 25)\n",
        "period = '2y'\n",
        "interval = '1d'\n",
        "horizon = 'next5'\n",
        "directory='/content/samples_3'\n",
        "stocks_3 = download_data(tickers_3, period=period, interval=interval)\n",
        "samples_3 = generate_samples(stocks_3, num_samples=num_samples, sample_size=sample_size, horizon=horizon, output_directory=directory)\n",
        "\n",
        "# Samples 4: Utilizando intervalos de 1 semana, em um período de 5y, com t+5 como horizonte (6 semanas após o final da amostra)\n",
        "tickers_4 = rd.sample(tickers, 25)\n",
        "period = '5y'\n",
        "interval = '1wk'\n",
        "horizon = 'next5'\n",
        "directory='/content/samples_4'\n",
        "stocks_4 = download_data(tickers_4, period=period, interval=interval)\n",
        "samples_4 = generate_samples(stocks_4, num_samples=num_samples, sample_size=sample_size, horizon=horizon, output_directory=directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxG1J7AgFBdQ"
      },
      "outputs": [],
      "source": [
        "## Combinando samples gerados em um único dataframe\n",
        "# Se quiser salvar um arquivo zip com dados no Drive, descomentar linha abaixo e mudar parâmetro `download` para `True`\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "merged_samples = merge_samples([samples_1, samples_2, samples_3, samples_4], download=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Gerando datasets de treinamento e teste utilizando ImageDataGenerators para melhorar o consumo de memória\n",
        "# X_train, y_train, X_test, y_test = prepare_dataset(merged_samples, image_size=(128, 128), test_split=0.2)\n",
        "train_generator, test_generator, label_encoder = prepare_dataset(merged_samples, image_size=(128, 128), test_split=0.2, batch_size=32)"
      ],
      "metadata": {
        "id": "cikIhAySKkiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwz4J2Iq7fvQ"
      },
      "source": [
        "# Arquitetura e treinamento da rede\n",
        "Nesta seção, é definida a arquitetura da rede neural, bem como é realizado o seu treinamento com base nos datasets gerados na seção anterior. A arquitetura dessa rede é inspirada na arquitetura da LeNet-5, mas com algumas otimizações mais modernas, a exemplo do uso da ReLU como função de ativação das camadas convolucionais e da adição de mais um bloco convolucional para aumentar a profundidade da imagem. O dropout é definido como 30% em cada bloco, o filtro tem 3x3px em todas as camadas, e o stride e o padding não foram modificados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t71eU1cZg68X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "293242a1-28bc-437b-cf0e-2d1d0d03568e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"my_lenet\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_lenet\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m8,388,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,711,587\u001b[0m (33.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,711,587</span> (33.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,710,371\u001b[0m (33.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,710,371</span> (33.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Definição da arquitetura da rede utilizada\n",
        "# A rede foi inspirada na LeNet-5 que vimos em aula, mas adicionei mais blocos convolucionais\n",
        "def my_lenet(hidd_neu=128, hidd_act='relu', do_freq=0.3):\n",
        "    inputs = tf.keras.layers.Input(shape=(128,128,3))\n",
        "\n",
        "    c1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    c1 = tf.keras.layers.BatchNormalization()(c1)\n",
        "    c1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(c1)\n",
        "    s2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c1)\n",
        "    s2 = tf.keras.layers.Dropout(do_freq)(s2)\n",
        "\n",
        "    c3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(s2)\n",
        "    c3 = tf.keras.layers.BatchNormalization()(c3)\n",
        "    c3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(c3)\n",
        "    s4 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c3)\n",
        "    s4 = tf.keras.layers.Dropout(do_freq)(s4)\n",
        "\n",
        "    c5 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(s4)\n",
        "    c5 = tf.keras.layers.BatchNormalization()(c5)\n",
        "    c5 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(c5)\n",
        "    s6 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c5)\n",
        "    s6 = tf.keras.layers.Dropout(do_freq)(s6)\n",
        "\n",
        "    flat = tf.keras.layers.Flatten()(s6)\n",
        "    f7 = tf.keras.layers.Dense(256, activation='relu')(flat)\n",
        "    f7 = tf.keras.layers.BatchNormalization()(f7)\n",
        "    f7 = tf.keras.layers.Dropout(do_freq)(f7)\n",
        "    f8 = tf.keras.layers.Dense(128, activation='relu')(f7)\n",
        "    f8 = tf.keras.layers.BatchNormalization()(f8)\n",
        "    f8 = tf.keras.layers.Dropout(do_freq)(f8)\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(f8)\n",
        "\n",
        "    return tf.keras.models.Model(inputs, outputs, name='my_lenet')\n",
        "\n",
        "model = my_lenet()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TNc1v0MisLH"
      },
      "outputs": [],
      "source": [
        "## Compilando e definindo checkpoints do modelo para otimizar treinamento\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='best_model.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEGLa4aQ7-fc"
      },
      "outputs": [],
      "source": [
        "## Treinando o modelo para 100 épocas (usando ImageDataGenerators por conta de memória)\n",
        "epochs = 100\n",
        "\n",
        "H = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[model_checkpoint_callback, early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtxEZGtdpbFj"
      },
      "outputs": [],
      "source": [
        "## Apresentando resultados do modelo com dados de teste\n",
        "results = model.evaluate(test_generator, steps=len(test_generator))\n",
        "\n",
        "print(f\"Final Test Loss: {results[0]:.4f}\")\n",
        "print(f\"Final Test Accuracy: {results[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4ru-3o_EOK1"
      },
      "outputs": [],
      "source": [
        "## Reaproveitando código de aula para plotar a matriz de confusão\n",
        "# Prevendo os valores de Y para os Xs de teste\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Criando a matriz de confusão\n",
        "cm = confusion_matrix(test_generator.labels, y_pred)\n",
        "\n",
        "# Apresentando a matriz de confusão utilizando a função sugerida\n",
        "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(2))\n",
        "display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM-JbG9IEeUl"
      },
      "outputs": [],
      "source": [
        "## Reaproveitando código de aula para calcular métricas de qualidade do modelo\n",
        "# Calculando a acurácia geral\n",
        "overallAccuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "print(f\"Overall Accuracy: {overallAccuracy}\")\n",
        "print(\"-----\")\n",
        "\n",
        "for i in range(2):\n",
        "  # Calculando e apresentando o erro de omissão\n",
        "  referenceValues = np.sum(cm[i,:])\n",
        "  correctlyClassified = np.max(cm[i,:])\n",
        "  omittedValues = referenceValues - correctlyClassified\n",
        "  omissionError = round(omittedValues / referenceValues*100, 4)\n",
        "  print(f\"Erro de omissão para {i} = {omissionError}%\")\n",
        "\n",
        "  # Calculando e apresentando o erro de comissão\n",
        "  classifiedValues = np.sum(cm[:,i])\n",
        "  correctlyClassified_1 = np.max(cm[:,i])\n",
        "  committedValues = classifiedValues - correctlyClassified\n",
        "  commissionError = round(committedValues / classifiedValues*100, 4)\n",
        "  print(f\"Erro de comissão para {i} = {commissionError}%\")\n",
        "\n",
        "  print(\"-----\")\n",
        "\n",
        "# Calculando o F1-Score\n",
        "f1 = f1_score(test_generator.classes, y_pred)\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para gerar gráfico da evolução da acurácia e da perda\n",
        "fig, ax1 = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_xticks(np.arange(epochs))\n",
        "ax1.set_ylabel('Accuracy', color=color)\n",
        "ax1.plot(H.history[\"val_accuracy\"], '--', label=\"val_acc\", color=color)\n",
        "ax1.plot(H.history[\"accuracy\"], label=\"train_acc\", color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Loss', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(H.history[\"val_loss\"], '--', label=\"val_loss\", color=color)\n",
        "ax2.plot(H.history[\"loss\"], label=\"train_loss\",color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.legend()\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c53_HKksbVcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_ta = merge_samples([samples_1], label_column='label_ta')\n",
        "train_generator, test_generator, label_encoder = prepare_dataset(merged_ta, label='label_ta', image_size=(128, 128), test_split=0.2, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C5P8sWz8rks",
        "outputId": "01c12397-b7da-40c2-ed8f-a2f82554d957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mesclando metadados...\n",
            "Total antes da limpeza: 16000 amostras\n",
            "Total após limpeza: 16000 amostras\n",
            "\n",
            "Preparando datasets: divisão treino/teste = 80%/20%\n",
            "Codificação dos labels: {'down': np.int64(0), 'neutral': np.int64(1), 'up': np.int64(2)}\n",
            "Divisão: 12800 treino, 3200 teste\n",
            "Found 12800 validated image filenames belonging to 3 classes.\n",
            "Found 3200 validated image filenames belonging to 3 classes.\n",
            "\n",
            "Datasets preparados com 3 classes\n",
            "  Treino: 12800 imagens\n",
            "  Teste: 3200 imagens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Treinando o modelo para 100 épocas (usando ImageDataGenerators por conta de memória)\n",
        "epochs = 40\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='best_model_ta.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "H = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[model_checkpoint_callback, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tN90QRF9Y_y",
        "outputId": "c9b7a923-0696-4a9d-cf77-244db3186729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5636 - loss: 1.0806\n",
            "Epoch 1: val_loss improved from inf to 0.68362, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 1s/step - accuracy: 0.5639 - loss: 1.0800 - val_accuracy: 0.7844 - val_loss: 0.6836\n",
            "Epoch 2/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7600 - loss: 0.6470\n",
            "Epoch 2: val_loss did not improve from 0.68362\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 1s/step - accuracy: 0.7600 - loss: 0.6470 - val_accuracy: 0.7284 - val_loss: 0.6966\n",
            "Epoch 3/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7723 - loss: 0.5862\n",
            "Epoch 3: val_loss improved from 0.68362 to 0.53736, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 1s/step - accuracy: 0.7723 - loss: 0.5862 - val_accuracy: 0.7844 - val_loss: 0.5374\n",
            "Epoch 4/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7848 - loss: 0.5376\n",
            "Epoch 4: val_loss improved from 0.53736 to 0.51679, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 1s/step - accuracy: 0.7848 - loss: 0.5376 - val_accuracy: 0.7947 - val_loss: 0.5168\n",
            "Epoch 5/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8058 - loss: 0.4722\n",
            "Epoch 5: val_loss did not improve from 0.51679\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 1s/step - accuracy: 0.8058 - loss: 0.4722 - val_accuracy: 0.7972 - val_loss: 0.5383\n",
            "Epoch 6/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8170 - loss: 0.4382\n",
            "Epoch 6: val_loss improved from 0.51679 to 0.37941, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 1s/step - accuracy: 0.8170 - loss: 0.4382 - val_accuracy: 0.8353 - val_loss: 0.3794\n",
            "Epoch 7/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8640 - loss: 0.3316\n",
            "Epoch 7: val_loss improved from 0.37941 to 0.30517, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 1s/step - accuracy: 0.8640 - loss: 0.3316 - val_accuracy: 0.8891 - val_loss: 0.3052\n",
            "Epoch 8/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8936 - loss: 0.2675\n",
            "Epoch 8: val_loss improved from 0.30517 to 0.24982, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 1s/step - accuracy: 0.8936 - loss: 0.2675 - val_accuracy: 0.9003 - val_loss: 0.2498\n",
            "Epoch 9/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9162 - loss: 0.2189\n",
            "Epoch 9: val_loss improved from 0.24982 to 0.23351, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 1s/step - accuracy: 0.9162 - loss: 0.2189 - val_accuracy: 0.9062 - val_loss: 0.2335\n",
            "Epoch 10/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9280 - loss: 0.1873\n",
            "Epoch 10: val_loss improved from 0.23351 to 0.11875, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 1s/step - accuracy: 0.9280 - loss: 0.1873 - val_accuracy: 0.9634 - val_loss: 0.1188\n",
            "Epoch 11/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9500 - loss: 0.1343\n",
            "Epoch 11: val_loss did not improve from 0.11875\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 1s/step - accuracy: 0.9500 - loss: 0.1343 - val_accuracy: 0.9628 - val_loss: 0.1262\n",
            "Epoch 12/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9627 - loss: 0.1051\n",
            "Epoch 12: val_loss improved from 0.11875 to 0.10445, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 1s/step - accuracy: 0.9627 - loss: 0.1051 - val_accuracy: 0.9734 - val_loss: 0.1045\n",
            "Epoch 13/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9679 - loss: 0.0896\n",
            "Epoch 13: val_loss did not improve from 0.10445\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 1s/step - accuracy: 0.9679 - loss: 0.0896 - val_accuracy: 0.9666 - val_loss: 0.1475\n",
            "Epoch 14/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9713 - loss: 0.0793\n",
            "Epoch 14: val_loss improved from 0.10445 to 0.08053, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 1s/step - accuracy: 0.9713 - loss: 0.0793 - val_accuracy: 0.9803 - val_loss: 0.0805\n",
            "Epoch 15/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9719 - loss: 0.0744\n",
            "Epoch 15: val_loss improved from 0.08053 to 0.05520, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 1s/step - accuracy: 0.9719 - loss: 0.0744 - val_accuracy: 0.9850 - val_loss: 0.0552\n",
            "Epoch 16/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9805 - loss: 0.0552\n",
            "Epoch 16: val_loss did not improve from 0.05520\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 1s/step - accuracy: 0.9805 - loss: 0.0552 - val_accuracy: 0.9769 - val_loss: 0.0820\n",
            "Epoch 17/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9675 - loss: 0.0977\n",
            "Epoch 17: val_loss did not improve from 0.05520\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 1s/step - accuracy: 0.9675 - loss: 0.0977 - val_accuracy: 0.9822 - val_loss: 0.0672\n",
            "Epoch 18/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9806 - loss: 0.0555\n",
            "Epoch 18: val_loss improved from 0.05520 to 0.05333, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 1s/step - accuracy: 0.9806 - loss: 0.0555 - val_accuracy: 0.9894 - val_loss: 0.0533\n",
            "Epoch 19/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9858 - loss: 0.0419\n",
            "Epoch 19: val_loss improved from 0.05333 to 0.05096, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 1s/step - accuracy: 0.9858 - loss: 0.0419 - val_accuracy: 0.9900 - val_loss: 0.0510\n",
            "Epoch 20/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9851 - loss: 0.0423\n",
            "Epoch 20: val_loss did not improve from 0.05096\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 1s/step - accuracy: 0.9851 - loss: 0.0423 - val_accuracy: 0.9906 - val_loss: 0.0571\n",
            "Epoch 21/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9849 - loss: 0.0393\n",
            "Epoch 21: val_loss improved from 0.05096 to 0.04743, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 1s/step - accuracy: 0.9849 - loss: 0.0393 - val_accuracy: 0.9912 - val_loss: 0.0474\n",
            "Epoch 22/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9860 - loss: 0.0375\n",
            "Epoch 22: val_loss did not improve from 0.04743\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 1s/step - accuracy: 0.9860 - loss: 0.0375 - val_accuracy: 0.9634 - val_loss: 0.1164\n",
            "Epoch 23/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9900 - loss: 0.0276\n",
            "Epoch 23: val_loss did not improve from 0.04743\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 1s/step - accuracy: 0.9900 - loss: 0.0276 - val_accuracy: 0.9869 - val_loss: 0.0729\n",
            "Epoch 24/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9878 - loss: 0.0357\n",
            "Epoch 24: val_loss did not improve from 0.04743\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 1s/step - accuracy: 0.9878 - loss: 0.0357 - val_accuracy: 0.9884 - val_loss: 0.0605\n",
            "Epoch 25/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9890 - loss: 0.0358\n",
            "Epoch 25: val_loss did not improve from 0.04743\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 1s/step - accuracy: 0.9890 - loss: 0.0358 - val_accuracy: 0.9922 - val_loss: 0.0495\n",
            "Epoch 26/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0267\n",
            "Epoch 26: val_loss did not improve from 0.04743\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0267 - val_accuracy: 0.9909 - val_loss: 0.0568\n",
            "Epoch 27/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9890 - loss: 0.0347\n",
            "Epoch 27: val_loss improved from 0.04743 to 0.04118, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 1s/step - accuracy: 0.9890 - loss: 0.0347 - val_accuracy: 0.9931 - val_loss: 0.0412\n",
            "Epoch 28/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0292\n",
            "Epoch 28: val_loss did not improve from 0.04118\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0292 - val_accuracy: 0.9778 - val_loss: 0.1180\n",
            "Epoch 29/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0213\n",
            "Epoch 29: val_loss did not improve from 0.04118\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0213 - val_accuracy: 0.9841 - val_loss: 0.0625\n",
            "Epoch 30/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9859 - loss: 0.0431\n",
            "Epoch 30: val_loss did not improve from 0.04118\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 1s/step - accuracy: 0.9859 - loss: 0.0431 - val_accuracy: 0.9922 - val_loss: 0.0452\n",
            "Epoch 31/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0276\n",
            "Epoch 31: val_loss improved from 0.04118 to 0.04001, saving model to best_model_ta.weights.h5\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0276 - val_accuracy: 0.9937 - val_loss: 0.0400\n",
            "Epoch 32/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0227\n",
            "Epoch 32: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0227 - val_accuracy: 0.9928 - val_loss: 0.0519\n",
            "Epoch 33/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0218\n",
            "Epoch 33: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0218 - val_accuracy: 0.8697 - val_loss: 0.5627\n",
            "Epoch 34/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9902 - loss: 0.0245\n",
            "Epoch 34: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 1s/step - accuracy: 0.9902 - loss: 0.0245 - val_accuracy: 0.9922 - val_loss: 0.0466\n",
            "Epoch 35/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9928 - loss: 0.0225\n",
            "Epoch 35: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 1s/step - accuracy: 0.9928 - loss: 0.0225 - val_accuracy: 0.9919 - val_loss: 0.0468\n",
            "Epoch 36/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9940 - loss: 0.0192\n",
            "Epoch 36: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 1s/step - accuracy: 0.9940 - loss: 0.0192 - val_accuracy: 0.9928 - val_loss: 0.0526\n",
            "Epoch 37/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9925 - loss: 0.0227\n",
            "Epoch 37: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 1s/step - accuracy: 0.9925 - loss: 0.0227 - val_accuracy: 0.9881 - val_loss: 0.0484\n",
            "Epoch 38/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0268\n",
            "Epoch 38: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0268 - val_accuracy: 0.9919 - val_loss: 0.0444\n",
            "Epoch 39/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9938 - loss: 0.0186\n",
            "Epoch 39: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 1s/step - accuracy: 0.9938 - loss: 0.0186 - val_accuracy: 0.9931 - val_loss: 0.0504\n",
            "Epoch 40/40\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0180\n",
            "Epoch 40: val_loss did not improve from 0.04001\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0180 - val_accuracy: 0.9941 - val_loss: 0.0476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "drive_path = Path('/content/drive')\n",
        "main_dir = Path('/content/')\n",
        "model_filename = f\"best_model_ta.weights.h5\"\n",
        "model_path = main_dir / model_filename\n",
        "drive_destination = Path('/content/drive/MyDrive') / model_filename\n",
        "shutil.move(str(model_path), str(drive_destination))\n",
        "print(f\"Dataset salvo: {drive_destination}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "W3zxOiy-hQJA",
        "outputId": "ecfeafe6-c59d-4d02-d1d1-89ba858a8a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-172170060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"best_model_ta.weights.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Apresentando resultados do modelo com dados de teste\n",
        "results = model.evaluate(test_generator, steps=len(test_generator))\n",
        "\n",
        "print(f\"Final Test Loss: {results[0]:.4f}\")\n",
        "print(f\"Final Test Accuracy: {results[1]:.4f}\")"
      ],
      "metadata": {
        "id": "BxPs7gSK9hvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para plotar a matriz de confusão\n",
        "# Prevendo os valores de Y para os Xs de teste\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Criando a matriz de confusão\n",
        "cm = confusion_matrix(test_generator.labels, y_pred)\n",
        "\n",
        "# # Apresentando a matriz de confusão utilizando a função sugerida\n",
        "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(3))\n",
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OWo1jvUR9iQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para calcular métricas de qualidade do modelo\n",
        "# Calculando a acurácia geral\n",
        "overallAccuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "print(f\"Overall Accuracy: {overallAccuracy}\")\n",
        "print(\"-----\")\n",
        "\n",
        "for i in range(2):\n",
        "  # Calculando e apresentando o erro de omissão\n",
        "  referenceValues = np.sum(cm[i,:])\n",
        "  correctlyClassified = np.max(cm[i,:])\n",
        "  omittedValues = referenceValues - correctlyClassified\n",
        "  omissionError = round(omittedValues / referenceValues*100, 4)\n",
        "  print(f\"Erro de omissão para {i} = {omissionError}%\")\n",
        "\n",
        "  # Calculando e apresentando o erro de comissão\n",
        "  classifiedValues = np.sum(cm[:,i])\n",
        "  correctlyClassified_1 = np.max(cm[:,i])\n",
        "  committedValues = classifiedValues - correctlyClassified\n",
        "  commissionError = round(committedValues / classifiedValues*100, 4)\n",
        "  print(f\"Erro de comissão para {i} = {commissionError}%\")\n",
        "\n",
        "  print(\"-----\")\n",
        "\n",
        "# Calculando o F1-Score\n",
        "f1 = f1_score(test_generator.classes, y_pred)\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "aTqEizug9lnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para gerar gráfico da evolução da acurácia e da perda\n",
        "fig, ax1 = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_xticks(np.arange(epochs))\n",
        "ax1.set_ylabel('Accuracy', color=color)\n",
        "ax1.plot(H.history[\"val_accuracy\"], '--', label=\"val_acc\", color=color)\n",
        "ax1.plot(H.history[\"accuracy\"], label=\"train_acc\", color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Loss', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(H.history[\"val_loss\"], '--', label=\"val_loss\", color=color)\n",
        "ax2.plot(H.history[\"loss\"], label=\"train_loss\",color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.legend()\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TuLk4CQP9pWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_calc = merge_samples([samples_1], label_column='label_calc')\n",
        "train_generator, test_generator, label_encoder = prepare_dataset(merged_calc, image_size=(128, 128), test_split=0.2, batch_size=32)"
      ],
      "metadata": {
        "id": "n-rS2-JT9DOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Treinando o modelo para 100 épocas (usando ImageDataGenerators por conta de memória)\n",
        "epochs = 40\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='best_model_calc.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "H = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[model_checkpoint_callback, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "-W8p3HTb9Zjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_path = Path('/content/drive')\n",
        "main_dir = Path('/content/')\n",
        "model_filename = f\"best_model_calc.weights.h5\"\n",
        "model_path = main_dir / model_filename\n",
        "drive_destination = Path('/content/drive/MyDrive') / model_filename\n",
        "shutil.move(str(model_path), str(drive_destination))\n",
        "print(f\"Dataset salvo: {drive_destination}\")"
      ],
      "metadata": {
        "id": "r7Q62bPkiaCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Apresentando resultados do modelo com dados de teste\n",
        "results = model.evaluate(test_generator, steps=len(test_generator))\n",
        "\n",
        "print(f\"Final Test Loss: {results[0]:.4f}\")\n",
        "print(f\"Final Test Accuracy: {results[1]:.4f}\")"
      ],
      "metadata": {
        "id": "bPIuML2d9ze2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para plotar a matriz de confusão\n",
        "# Prevendo os valores de Y para os Xs de teste\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Criando a matriz de confusão\n",
        "cm = confusion_matrix(test_generator.labels, y_pred)\n",
        "\n",
        "# Apresentando a matriz de confusão utilizando a função sugerida\n",
        "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(3))\n",
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mJHM1X4H9yH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para calcular métricas de qualidade do modelo\n",
        "# Calculando a acurácia geral\n",
        "overallAccuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "print(f\"Overall Accuracy: {overallAccuracy}\")\n",
        "print(\"-----\")\n",
        "\n",
        "for i in range(2):\n",
        "  # Calculando e apresentando o erro de omissão\n",
        "  referenceValues = np.sum(cm[i,:])\n",
        "  correctlyClassified = np.max(cm[i,:])\n",
        "  omittedValues = referenceValues - correctlyClassified\n",
        "  omissionError = round(omittedValues / referenceValues*100, 4)\n",
        "  print(f\"Erro de omissão para {i} = {omissionError}%\")\n",
        "\n",
        "  # Calculando e apresentando o erro de comissão\n",
        "  classifiedValues = np.sum(cm[:,i])\n",
        "  correctlyClassified_1 = np.max(cm[:,i])\n",
        "  committedValues = classifiedValues - correctlyClassified\n",
        "  commissionError = round(committedValues / classifiedValues*100, 4)\n",
        "  print(f\"Erro de comissão para {i} = {commissionError}%\")\n",
        "\n",
        "  print(\"-----\")\n",
        "\n",
        "# Calculando o F1-Score\n",
        "f1 = f1_score(test_generator.classes, y_pred)\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "dLb5d7XC9qY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reaproveitando código de aula para gerar gráfico da evolução da acurácia e da perda\n",
        "fig, ax1 = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_xticks(np.arange(epochs))\n",
        "ax1.set_ylabel('Accuracy', color=color)\n",
        "ax1.plot(H.history[\"val_accuracy\"], '--', label=\"val_acc\", color=color)\n",
        "ax1.plot(H.history[\"accuracy\"], label=\"train_acc\", color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Loss', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(H.history[\"val_loss\"], '--', label=\"val_loss\", color=color)\n",
        "ax2.plot(H.history[\"loss\"], label=\"train_loss\",color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.legend()\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vt4Jf5O69p_j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}